{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"ENB2012_data.xlsx\")\n",
    "    # Get features from dropping outputs\n",
    "X = data.drop(['Y1', 'Y2'], axis=1).values\n",
    "# Get outputs from data\n",
    "y_1= ((data['Y1']).values).reshape(-1, 1)\n",
    "y_2= ((data['Y2']).values).reshape(-1, 1)\n",
    "# Import libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Set paramaters for random forest regressor\n",
    "param_grid = {\n",
    "    'max_depth': [50,150,250],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [2,3],\n",
    "    'n_estimators': [10,50,100,250,500]\n",
    "}\n",
    "# Set parameters for ridge regressor\n",
    "ridge_params={\n",
    "    'alpha':[0.001,0.01,0.1, 1.0, 10.0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold,cross_val_score\n",
    "cv=RepeatedKFold(n_splits=10,n_repeats=10,random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y_1 , test_size=0.2 , random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for ridge regression {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "temp_ridge=Ridge()\n",
    "grid_search_ridge=GridSearchCV(estimator = temp_ridge, param_grid = ridge_params, cv = cv, n_jobs = -1)\n",
    "grid_search_ridge.fit(X_train,y_train.ravel())\n",
    "print(\"Best parameter for ridge regression\",grid_search_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Ridge(**grid_search_ridge.best_params_)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0687340284186253\n",
      "0.2448154589007154\n"
     ]
    }
   ],
   "source": [
    "scores_ridge = cross_val_score(model, X_train, y_train,scoring=\"neg_mean_absolute_error\", cv=cv)\n",
    "print(-scores_ridge.mean())\n",
    "print(scores_ridge.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.589594321769248\n",
      "1.7913033726179532\n"
     ]
    }
   ],
   "source": [
    "scores_ridge = cross_val_score(model, X_train, y_train,scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "print(-scores_ridge.mean())\n",
    "print(scores_ridge.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold,KFold,cross_val_score,GridSearchCV,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def problem2(filename):\n",
    "    # Read data using pandas library\n",
    "    data = pd.read_csv(filename, sep = ';')\n",
    "    #Converting dependent variable categorical to dummy\n",
    "    y = pd.get_dummies(data['y'], columns = ['y'], prefix = ['y'], drop_first = True)\n",
    "    y=y.values.reshape(-1, 1)\n",
    "    # Firstly I divided categorical data different parts. \n",
    "    # data_c includes client features\n",
    "    # I used labelencoder because it gives better result\n",
    "    data_c = data.iloc[: , 0:7]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    data_c['job']      = labelencoder_X.fit_transform(data_c['job']) \n",
    "    data_c['marital']  = labelencoder_X.fit_transform(data_c['marital']) \n",
    "    data_c['education']= labelencoder_X.fit_transform(data_c['education']) \n",
    "    data_c['default']  = labelencoder_X.fit_transform(data_c['default']) \n",
    "    data_c['housing']  = labelencoder_X.fit_transform(data_c['housing']) \n",
    "    data_c['loan']     = labelencoder_X.fit_transform(data_c['loan']) \n",
    "    # The client age is divided four range. I get the idea different projects. It is useful\n",
    "    data_c.loc[data_c['age'] <= 32, 'age'] = 1\n",
    "    data_c.loc[(data_c['age'] > 32) & (data_c['age'] <= 47), 'age'] = 2\n",
    "    data_c.loc[(data_c['age'] > 47) & (data_c['age'] <= 70), 'age'] = 3\n",
    "    data_c.loc[(data_c['age'] > 70) & (data_c['age'] <= 98), 'age'] = 4\n",
    "    # try to convert contact, month, day_of_week data to numerical\n",
    "    data_r = data.iloc[: , 7:11]\n",
    "    data[(data['duration'] == 0)]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    data_r['contact']     = labelencoder_X.fit_transform(data_r['contact']) \n",
    "    data_r['month']       = labelencoder_X.fit_transform(data_r['month']) \n",
    "    data_r['day_of_week'] = labelencoder_X.fit_transform(data_r['day_of_week']) \n",
    "    # I did samething like before  I did to age column\n",
    "    data_r.loc[data['duration'] <= 102, 'duration'] = 1\n",
    "    data_r.loc[(data['duration'] > 102) & (data_r['duration'] <= 180)  , 'duration']    = 2\n",
    "    data_r.loc[(data['duration'] > 180) & (data_r['duration'] <= 319)  , 'duration']   = 3\n",
    "    data_r.loc[(data['duration'] > 319) & (data_r['duration'] <= 644.5), 'duration'] = 4\n",
    "    data_r.loc[data['duration']  > 644.5, 'duration'] = 5\n",
    "\n",
    "    data_s = data.loc[: , ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']]\n",
    "    data_o = data.loc[: , ['campaign', 'pdays','previous', 'poutcome']]\n",
    "    data_o['poutcome'].replace(['nonexistent', 'failure', 'success'], [1,2,3], inplace  = True)\n",
    "    # To combine data after data preprocessing\n",
    "    data_final= pd.concat([data_c, data_r, data_s, data_o], axis = 1)\n",
    "    data_final = data_final[['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "                        'contact', 'month', 'day_of_week', 'duration', 'emp.var.rate', 'cons.price.idx', \n",
    "                        'cons.conf.idx', 'euribor3m', 'nr.employed', 'campaign', 'pdays', 'previous', 'poutcome']]\n",
    "    # Split data \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data_final, y.ravel(), test_size = 0.2, random_state = 101)\n",
    "    # Scale data\n",
    "    sc_X = StandardScaler()\n",
    "    X_scaled = sc_X.fit_transform(data_final)\n",
    "    # X_test = sc_X.transform(X_test)\n",
    "    # create cross validation method\n",
    "    cv=RepeatedKFold(n_splits=5,n_repeats=5,random_state=True)\n",
    "    # Create a loop that is range from 10^-4 to 10^4\n",
    "    # And put each values as C parameter\n",
    "    all_scores=[]\n",
    "    for x in np.logspace(-4,4,20):\n",
    "        model=LogisticRegression(C=x)\n",
    "        model.fit(X_scaled,y.ravel())\n",
    "        scores=cross_val_score(model, X_scaled, y.ravel(),scoring=\"roc_auc\", cv=cv)\n",
    "        all_scores.append(scores.mean())\n",
    "\n",
    "    # Plot scores\n",
    "    plt.plot(np.logspace(-4,4,20,endpoint=True),all_scores,'-gD')\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylabel(\"Mean Auc Score\")\n",
    "    plt.title(\"Logistic Regression Model\")\n",
    "    # Create paramater list \n",
    "    param_grid = {\n",
    "    'max_depth': [50,150,250],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [2,3],\n",
    "    'n_estimators': [10,50,100,250,500,1000]\n",
    "    }\n",
    "    # Create cross validation method\n",
    "    cv=RepeatedKFold(n_splits=3,n_repeats=3,random_state=True)\n",
    "    rf = RandomForestRegressor()\n",
    "    grid_search_logi = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                            cv = cv, n_jobs = -1)\n",
    "    \n",
    "    grid_search_logi.fit(X_scaled,y.ravel())\n",
    "    # get best parameters for random forest regressor\n",
    "    print(\"Best parameters of Random regressor\",grid_search_logi.best_params_);\n",
    "    last_model_logi=RandomForestRegressor(**grid_search_logi.best_params_)\n",
    "    scores = cross_val_score(last_model_logi, X_scaled, y.ravel(),scoring=\"roc_auc\", cv=cv)\n",
    "    scores.mean()\n",
    "    # create neural network using MLPClassifier\n",
    "    mlp_classifier=MLPClassifier(max_iter=500)\n",
    "    # Create parameter list\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(10,10,10),(10,10,10,10),(10,10,10,10,10),(10,10,10,10,10,10)],\n",
    "        'alpha': [0.00001, 0.0001,0.001, 0.01, 0.1],\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator = mlp_classifier, param_grid = parameter_space, \n",
    "                            cv = cv, n_jobs = -1,scoring='roc_auc')\n",
    "    grid_search.fit(X_scaled,y.ravel())\n",
    "    print(\"Best parameters for Neural Network\",grid_search.best_params_)\n",
    "    # Variables for average classification report\n",
    "    from sklearn.metrics import classification_report,make_scorer,accuracy_score\n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    #Make our customer score\n",
    "    def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "        originalclass.extend(y_true)\n",
    "        predictedclass.extend(y_pred)\n",
    "        return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "\n",
    "    logistic_reg=LogisticRegression(C=1)\n",
    "    best_neural=MLPClassifier(**grid_search.best_params_)\n",
    "    best_randomforest=RandomForestClassifier(**grid_search_logi.best_params_)\n",
    "    # best_randomforest.fit(X_train,y_train.ravel())\n",
    "    # y_pred=best_randomforest.predict(X_test)\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=True)\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(logistic_reg, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for logistic regression\")\n",
    "    print(classification_report(originalclass, predictedclass)) \n",
    "    originalclass.clear()\n",
    "    predictedclass.clear()\n",
    "    nested_score = cross_val_score(best_neural, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for neural network\")\n",
    "    print(classification_report(originalclass, predictedclass)) \n",
    "    originalclass.clear()\n",
    "    predictedclass.clear()\n",
    "    nested_score = cross_val_score(best_randomforest, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for Random forest\")\n",
    "    print(classification_report(originalclass, predictedclass)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters of Random regressor {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1000}\n",
      "Best parameters for Neural Network {'alpha': 0.1, 'hidden_layer_sizes': (10, 10, 10, 10, 10)}\n",
      "classification report for logistic regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     36548\n",
      "           1       0.67      0.38      0.48      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.80      0.68      0.72     41188\n",
      "weighted avg       0.90      0.91      0.90     41188\n",
      "\n",
      "classification report for neural network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     36548\n",
      "           1       0.61      0.57      0.59      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.78      0.76      0.77     41188\n",
      "weighted avg       0.91      0.91      0.91     41188\n",
      "\n",
      "classification report for Random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     36548\n",
      "           1       0.64      0.48      0.55      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.79      0.72      0.75     41188\n",
      "weighted avg       0.90      0.91      0.91     41188\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "problem2('bank-additional-full.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11f4f9e024f345a762b367b953dda8a9d0d73d0ed685f40724d283ac032facc1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('sklearn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
