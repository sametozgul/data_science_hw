{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def problem1(filename):\n",
    "    # Read exel file \n",
    "    data=pd.read_excel(filename)\n",
    "    # Get features from dropping outputs\n",
    "    X = data.drop(['Y1', 'Y2'], axis=1).values\n",
    "    # Get outputs from data\n",
    "    y_1= ((data['Y1']).values).reshape(-1, 1)\n",
    "    y_2= ((data['Y2']).values).reshape(-1, 1)\n",
    "    # Import libraries\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    # Set paramaters for random forest regressor\n",
    "    param_grid = {\n",
    "        'max_depth': [50,150,250],\n",
    "        'min_samples_leaf': [1,2,3],\n",
    "        'min_samples_split': [2,3],\n",
    "        'n_estimators': [10,50,100,250,500]\n",
    "    }\n",
    "    # Set parameters for ridge regressor\n",
    "    ridge_params={\n",
    "        'alpha':[0.001,0.01,0.1, 1.0, 10.0]\n",
    "    }\n",
    "    # This list is used in loop. \n",
    "    # The outer loop iterate each output y_1 and y_2 and the inner loop iterate two types error\n",
    "    outputs=[y_1,y_2]\n",
    "    ridge_means=[]\n",
    "    ridge_std=[]\n",
    "    forest_means=[]\n",
    "    forest_std=[]\n",
    "    # Outer loop\n",
    "    for index,y_x in  enumerate(outputs):\n",
    "        # Inner loop\n",
    "        for score in [\"neg_mean_absolute_error\",\"neg_mean_squared_error\"]:\n",
    "            # Split data randomly.\n",
    "            X_train , X_test , y_train , y_test = train_test_split(X , y_x , test_size=0.2 , random_state =42)\n",
    "            # Scale data for get good model\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler=StandardScaler()\n",
    "            X_train=scaler.fit_transform(X_train)\n",
    "            X_test=scaler.transform(X_test)\n",
    "            # 10-fold 10-repetative cross validation method \n",
    "            from sklearn.model_selection import RepeatedKFold,cross_val_score\n",
    "            cv=RepeatedKFold(n_splits=10,n_repeats=10,random_state=True)\n",
    "            temp_ridge=Ridge()\n",
    "            # In this line, using gridsearchcv, we can get best parameters for ridge regression\n",
    "            grid_search_ridge=GridSearchCV(estimator = temp_ridge, param_grid = ridge_params, cv = cv, n_jobs = -1)\n",
    "            grid_search_ridge.fit(X_train,y_train.ravel())\n",
    "            print(\"Best parameter for ridge regression\",grid_search_ridge.best_params_)\n",
    "            # Using best parameters, the best model is created.\n",
    "            model=Ridge(**grid_search_ridge.best_params_)\n",
    "            model.fit(X_train,y_train)\n",
    "            # Using best model, we can get mean and standart deviation\n",
    "            scores_ridge = cross_val_score(model, X_train, y_train,scoring=score, cv=cv)\n",
    "            ridge_means.append(-scores_ridge.mean())\n",
    "            ridge_std.append(scores_ridge.std())\n",
    "            # Create a random forest regressor\n",
    "            rf = RandomForestRegressor()\n",
    "            # Find best parameters using grid search\n",
    "            grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = cv, n_jobs = -1)\n",
    "            grid_search.fit(X_train,y_train.ravel())\n",
    "            print(\"Best parameter for Random forest regression\",grid_search.best_params_)\n",
    "            # create a model using best parameters\n",
    "            last_model=RandomForestRegressor(**grid_search.best_params_)\n",
    "            scores_randomforest= cross_val_score(last_model, X_train, y_train.ravel(),scoring=score, cv=cv)\n",
    "            forest_means.append(-scores_randomforest.mean())\n",
    "            forest_std.append(scores_randomforest.std())\n",
    "            # print(\"RandomForest\",\"Y\",index+1,\" \",score,\"-----\",-scores.mean(),scores.std()\n",
    "    # In this line prettytable is used to print results as table.\n",
    "    from prettytable import PrettyTable\n",
    "    x=PrettyTable([\"-\",\"Mean Absolute Error\",\"*\",\"Mean Square Error\",\"/\"])\n",
    "    x.add_row([\"Output\",\"RandomForest\",\"RidgeRegression\",\"RandomForest\",\"RidgeRegression\"])\n",
    "    x.add_row([\"Y1\",str(forest_means[0])+u\"\\u00B1\"+str(forest_std[0]),str(ridge_means[0])+u\"\\u00B1\"+str(ridge_std[0]),\n",
    "                    str(forest_means[1])+u\"\\u00B1\"+str(forest_std[1]),str(ridge_means[1])+u\"\\u00B1\"+str(ridge_std[1])])\n",
    "    x.add_row([\"Y2\",str(forest_means[2])+u\"\\u00B1\"+str(forest_std[2]),str(ridge_means[2])+u\"\\u00B1\"+str(ridge_std[2]),\n",
    "                    str(forest_means[3])+u\"\\u00B1\"+str(forest_std[3]),str(ridge_means[3])+u\"\\u00B1\"+str(ridge_std[3])])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for ridge regression {'alpha': 0.1}\n",
      "Best parameter for Random forest regression {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best parameter for ridge regression {'alpha': 0.1}\n",
      "Best parameter for Random forest regression {'max_depth': 250, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best parameter for ridge regression {'alpha': 0.1}\n",
      "Best parameter for Random forest regression {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "Best parameter for ridge regression {'alpha': 0.1}\n",
      "Best parameter for Random forest regression {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "+--------+---------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------+\n",
      "|   -    |          Mean Absolute Error          |                   *                    |            Mean Square Error            |                  /                   |\n",
      "+--------+---------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------+\n",
      "| Output |              RandomForest             |            RidgeRegression             |               RandomForest              |           RidgeRegression            |\n",
      "|   Y1   | 0.3269955335096064±0.0479998565883446 | 2.0684062874150566±0.24478405555575394 | 0.24826960552234414±0.10061971286789874 | 8.589288373986665±1.791267376161846  |\n",
      "|   Y2   |  0.999799514542574±0.1582350909855546 | 2.2830741086533677±0.2724593537075571  |  2.7957592061379235±0.8485947796206003  | 10.481908726214302±2.523616365288306 |\n",
      "+--------+---------------------------------------+----------------------------------------+-----------------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "problem1(\"ENB2012_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,RepeatedKFold,KFold,cross_val_score,GridSearchCV,StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "def problem2(filename):\n",
    "    # Read data using pandas library\n",
    "    data = pd.read_csv(filename, sep = ';')\n",
    "    #Converting dependent variable categorical to dummy\n",
    "    y = pd.get_dummies(data['y'], columns = ['y'], prefix = ['y'], drop_first = True)\n",
    "    y=y.values.reshape(-1, 1)\n",
    "    # Firstly I divided categorical data different parts. \n",
    "    # data_c includes client features\n",
    "    # I used labelencoder because it gives better result\n",
    "    data_c = data.iloc[: , 0:7]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    data_c['job']      = labelencoder_X.fit_transform(data_c['job']) \n",
    "    data_c['marital']  = labelencoder_X.fit_transform(data_c['marital']) \n",
    "    data_c['education']= labelencoder_X.fit_transform(data_c['education']) \n",
    "    data_c['default']  = labelencoder_X.fit_transform(data_c['default']) \n",
    "    data_c['housing']  = labelencoder_X.fit_transform(data_c['housing']) \n",
    "    data_c['loan']     = labelencoder_X.fit_transform(data_c['loan']) \n",
    "\n",
    "    # try to convert contact, month, day_of_week data to numerical\n",
    "    data_r = data.iloc[: , 7:11]\n",
    "    data[(data['duration'] == 0)]\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    data_r['contact']     = labelencoder_X.fit_transform(data_r['contact']) \n",
    "    data_r['month']       = labelencoder_X.fit_transform(data_r['month']) \n",
    "    data_r['day_of_week'] = labelencoder_X.fit_transform(data_r['day_of_week']) \n",
    "\n",
    "    data_s = data.loc[: , ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']]\n",
    "    data_o = data.loc[: , ['campaign', 'pdays','previous', 'poutcome']]\n",
    "    data_o['poutcome'].replace(['nonexistent', 'failure', 'success'], [1,2,3], inplace  = True)\n",
    "    # To combine data after data preprocessing\n",
    "    data_final= pd.concat([data_c, data_r, data_s, data_o], axis = 1)\n",
    "    data_final = data_final[['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "                        'contact', 'month', 'day_of_week', 'duration', 'emp.var.rate', 'cons.price.idx', \n",
    "                        'cons.conf.idx', 'euribor3m', 'nr.employed', 'campaign', 'pdays', 'previous', 'poutcome']]\n",
    "    # Split data \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data_final, y.ravel(), test_size = 0.2, random_state = 101)\n",
    "    # Scale data\n",
    "    sc_X = StandardScaler()\n",
    "    X_scaled = sc_X.fit_transform(data_final)\n",
    "    # X_test = sc_X.transform(X_test)\n",
    "    # create cross validation method\n",
    "    cv=RepeatedKFold(n_splits=5,n_repeats=5,random_state=True)\n",
    "    # Create a loop that is range from 10^-4 to 10^4\n",
    "    # And put each values as C parameter\n",
    "    all_scores=[]\n",
    "    for x in np.logspace(-4,4,20):\n",
    "        model=LogisticRegression(C=x)\n",
    "        model.fit(X_scaled,y.ravel())\n",
    "        scores=cross_val_score(model, X_scaled, y.ravel(),scoring=\"roc_auc\", cv=cv)\n",
    "        all_scores.append(scores.mean())\n",
    "\n",
    "    # Plot scores\n",
    "    plt.plot(np.logspace(-4,4,20,endpoint=True),all_scores,'-gD')\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylabel(\"Mean Auc Score\")\n",
    "    plt.title(\"Logistic Regression Model\")\n",
    "    # Create paramater list \n",
    "    param_grid = {\n",
    "    'max_depth': [50,150,250],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [2,3],\n",
    "    'n_estimators': [10,50,100,250,500,1000]\n",
    "    }\n",
    "    # Create cross validation method\n",
    "    cv=RepeatedKFold(n_splits=3,n_repeats=3,random_state=True)\n",
    "    rf = RandomForestRegressor()\n",
    "    grid_search_logi = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                            cv = cv, n_jobs = -1)\n",
    "    \n",
    "    grid_search_logi.fit(X_scaled,y.ravel())\n",
    "    # get best parameters for random forest regressor\n",
    "    print(\"Best parameters of Random regressor\",grid_search_logi.best_params_);\n",
    "    last_model_logi=RandomForestRegressor(**grid_search_logi.best_params_)\n",
    "    scores = cross_val_score(last_model_logi, X_scaled, y.ravel(),scoring=\"roc_auc\", cv=cv)\n",
    "    scores.mean()\n",
    "    # create neural network using MLPClassifier\n",
    "    mlp_classifier=MLPClassifier(max_iter=500)\n",
    "    # Create parameter list\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(10,10,10),(10,10,10,10),(10,10,10,10,10),(10,10,10,10,10,10)],\n",
    "        'alpha': [0.00001, 0.0001,0.001, 0.01, 0.1],\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator = mlp_classifier, param_grid = parameter_space, \n",
    "                            cv = cv, n_jobs = -1,scoring='roc_auc')\n",
    "    grid_search.fit(X_scaled,y.ravel())\n",
    "    print(\"Best parameters for Neural Network\",grid_search.best_params_)\n",
    "    # Variables for average classification report\n",
    "    from sklearn.metrics import classification_report,make_scorer,accuracy_score\n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    #Make our customer score\n",
    "    def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "        originalclass.extend(y_true)\n",
    "        predictedclass.extend(y_pred)\n",
    "        return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "\n",
    "    logistic_reg=LogisticRegression(C=1)\n",
    "    best_neural=MLPClassifier(**grid_search.best_params_)\n",
    "    best_randomforest=RandomForestClassifier(**grid_search_logi.best_params_)\n",
    "    # best_randomforest.fit(X_train,y_train.ravel())\n",
    "    # y_pred=best_randomforest.predict(X_test)\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=True)\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(logistic_reg, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for logistic regression\")\n",
    "    print(classification_report(originalclass, predictedclass)) \n",
    "    originalclass.clear()\n",
    "    predictedclass.clear()\n",
    "    nested_score = cross_val_score(best_neural, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for neural network\")\n",
    "    print(classification_report(originalclass, predictedclass)) \n",
    "    originalclass.clear()\n",
    "    predictedclass.clear()\n",
    "    nested_score = cross_val_score(best_randomforest, X=X_scaled, y=y.ravel(), cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "    print(\"classification report for Random forest\")\n",
    "    print(classification_report(originalclass, predictedclass)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters of Random regressor {'max_depth': 150, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1000}\n",
      "Best parameters for Neural Network {'alpha': 0.1, 'hidden_layer_sizes': (10, 10, 10, 10)}\n",
      "classification report for logistic regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     36548\n",
      "           1       0.66      0.41      0.50      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.80      0.69      0.73     41188\n",
      "weighted avg       0.90      0.91      0.90     41188\n",
      "\n",
      "classification report for neural network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     36548\n",
      "           1       0.63      0.56      0.59      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.79      0.76      0.77     41188\n",
      "weighted avg       0.91      0.91      0.91     41188\n",
      "\n",
      "classification report for Random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     36548\n",
      "           1       0.67      0.52      0.58      4640\n",
      "\n",
      "    accuracy                           0.92     41188\n",
      "   macro avg       0.81      0.74      0.77     41188\n",
      "weighted avg       0.91      0.92      0.91     41188\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "problem2('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11f4f9e024f345a762b367b953dda8a9d0d73d0ed685f40724d283ac032facc1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('sklearn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
